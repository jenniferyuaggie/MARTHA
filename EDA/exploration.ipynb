{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5b128ef2586e1527017a6c07555a02f0df64fe85"
      },
      "cell_type": "code",
      "source": "# from https://www.kaggle.com/theoviel/load-the-totality-of-the-data\ndtypes = {\n        'MachineIdentifier':                                    'category',\n        'ProductName':                                          'category',\n        'EngineVersion':                                        'category',\n        'AppVersion':                                           'category',\n        'AvSigVersion':                                         'category',\n        'IsBeta':                                               'int8',\n        'RtpStateBitfield':                                     'float16',\n        'IsSxsPassiveMode':                                     'int8',\n        'DefaultBrowsersIdentifier':                            'float16',\n        'AVProductStatesIdentifier':                            'float32',\n        'AVProductsInstalled':                                  'float16',\n        'AVProductsEnabled':                                    'float16',\n        'HasTpm':                                               'int8',\n        'CountryIdentifier':                                    'int16',\n        'CityIdentifier':                                       'float32',\n        'OrganizationIdentifier':                               'float16',\n        'GeoNameIdentifier':                                    'float16',\n        'LocaleEnglishNameIdentifier':                          'int8',\n        'Platform':                                             'category',\n        'Processor':                                            'category',\n        'OsVer':                                                'category',\n        'OsBuild':                                              'int16',\n        'OsSuite':                                              'int16',\n        'OsPlatformSubRelease':                                 'category',\n        'OsBuildLab':                                           'category',\n        'SkuEdition':                                           'category',\n        'IsProtected':                                          'float16',\n        'AutoSampleOptIn':                                      'int8',\n        'PuaMode':                                              'category',\n        'SMode':                                                'float16',\n        'IeVerIdentifier':                                      'float16',\n        'SmartScreen':                                          'category',\n        'Firewall':                                             'float16',\n        'UacLuaenable':                                         'float32',\n        'Census_MDC2FormFactor':                                'category',\n        'Census_DeviceFamily':                                  'category',\n        'Census_OEMNameIdentifier':                             'float16',\n        'Census_OEMModelIdentifier':                            'float32',\n        'Census_ProcessorCoreCount':                            'float16',\n        'Census_ProcessorManufacturerIdentifier':               'float16',\n        'Census_ProcessorModelIdentifier':                      'float16',\n        'Census_ProcessorClass':                                'category',\n        'Census_PrimaryDiskTotalCapacity':                      'float32',\n        'Census_PrimaryDiskTypeName':                           'category',\n        'Census_SystemVolumeTotalCapacity':                     'float32',\n        'Census_HasOpticalDiskDrive':                           'int8',\n        'Census_TotalPhysicalRAM':                              'float32',\n        'Census_ChassisTypeName':                               'category',\n        'Census_InternalPrimaryDiagonalDisplaySizeInInches':    'float16',\n        'Census_InternalPrimaryDisplayResolutionHorizontal':    'float16',\n        'Census_InternalPrimaryDisplayResolutionVertical':      'float16',\n        'Census_PowerPlatformRoleName':                         'category',\n        'Census_InternalBatteryType':                           'category',\n        'Census_InternalBatteryNumberOfCharges':                'float32',\n        'Census_OSVersion':                                     'category',\n        'Census_OSArchitecture':                                'category',\n        'Census_OSBranch':                                      'category',\n        'Census_OSBuildNumber':                                 'int16',\n        'Census_OSBuildRevision':                               'int32',\n        'Census_OSEdition':                                     'category',\n        'Census_OSSkuName':                                     'category',\n        'Census_OSInstallTypeName':                             'category',\n        'Census_OSInstallLanguageIdentifier':                   'float16',\n        'Census_OSUILocaleIdentifier':                          'int16',\n        'Census_OSWUAutoUpdateOptionsName':                     'category',\n        'Census_IsPortableOperatingSystem':                     'int8',\n        'Census_GenuineStateName':                              'category',\n        'Census_ActivationChannel':                             'category',\n        'Census_IsFlightingInternal':                           'float16',\n        'Census_IsFlightsDisabled':                             'float16',\n        'Census_FlightRing':                                    'category',\n        'Census_ThresholdOptIn':                                'float16',\n        'Census_FirmwareManufacturerIdentifier':                'float16',\n        'Census_FirmwareVersionIdentifier':                     'float32',\n        'Census_IsSecureBootEnabled':                           'int8',\n        'Census_IsWIMBootEnabled':                              'float16',\n        'Census_IsVirtualDevice':                               'float16',\n        'Census_IsTouchEnabled':                                'int8',\n        'Census_IsPenCapable':                                  'int8',\n        'Census_IsAlwaysOnAlwaysConnectedCapable':              'float16',\n        'Wdft_IsGamer':                                         'float16',\n        'Wdft_RegionIdentifier':                                'float16',\n        'HasDetections':                                        'int8'\n        }",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# load the data\ntrain = pd.read_csv(\"../input/train.csv\",dtype = dtypes)\nID_col = train['MachineIdentifier']\ntrain.drop('MachineIdentifier', axis=1, inplace=True)\n# take a look at the head\ntrain.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3a0fd6ca5190a46eeac2a56efae8b6e1bad61be1"
      },
      "cell_type": "code",
      "source": "# Basic summary statistics\ntrain.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6a19e2078359f573dde147b7e16e70910c4a64ac"
      },
      "cell_type": "code",
      "source": "# Also check # of features available\ntrain.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "38e8323ce0342e8adf12c16f0a88a64b71a098cb",
        "_kg_hide-input": true,
        "_kg_hide-output": true
      },
      "cell_type": "code",
      "source": "# tweak from https://www.kaggle.com/jiegeng94/everyone-do-this-at-the-beginning\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            try:\n                c_min = df[col].min()\n                c_max = df[col].max()\n            except TypeError:\n                df[col] = df[col].astype('category')\n                continue\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\n%time\ntrain = reduce_mem_usage(train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3999fb014a6ccb2d0a19b47800cb649f0e662a01"
      },
      "cell_type": "markdown",
      "source": "So we have 81 features (1 column for ID, 1 column for response) and 8 millions rows in total for training. Dropping the ID column for now since it serves as the primary key and won't help as a feature.\n\nBefore moving on... how about checking NANs?\n\n# NULL value check"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "41717d7509c628b20c567db47cd87a23d61ed156",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "# Nan Values\nnull_counts = train.isnull().sum()/train.shape[0]\nprint(null_counts)\nprint(\"Columns with at least 1 NA:\",null_counts[null_counts > 0].index)\nprint(\"Count:\",len(null_counts[null_counts > 0].index))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "68f87d30a06b19e228fe274b02ff6aecb8b2565e"
      },
      "cell_type": "markdown",
      "source": "Ouch. 44 out of 81 features have missing values issue. We will need to come up with a way to handle this (rather than just throw away all the data with no record).\n\nPlus, the following 7 columns might be safely excluded (since they are mostly NANs):\n\n* DefaultBrowsersIdentifier\n* PuaMode\n* Census_ProcessorClass\n* Census_InternalBatteryType\n* Census_IsFlightingInternal\n* Census_ThresholdOptIn\n* Census_IsWIMBootEnabled"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e3e8fe9322c8173814e0e4594214dd54b59b9f23"
      },
      "cell_type": "code",
      "source": "half_nans = null_counts[null_counts > 0.5].index\nprint(\"Columns that are half NANs:\")\nfor c in half_nans:\n    print(\"Name:\",c,\", NAN ratio:\",null_counts[c])\nprint(\"Total count of half NAN columns:\",len(null_counts[null_counts > 0.5].index))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fa819e8d07dc1f74046d7ebbacc433a89d9168ba"
      },
      "cell_type": "code",
      "source": "train.drop(half_nans, axis=1, inplace=True)\nprint(train.columns.values)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e92de40d281b27bd8156e76985c18bb8ac4120f3"
      },
      "cell_type": "markdown",
      "source": "Now that we have eliminated 7 columns that are deemed to be mostly empty, how about the categorical columns? In order to process them, encoding is necessary."
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "4f7acb1c59f5dc5c8a38307a9904b7d421a13ccb"
      },
      "cell_type": "code",
      "source": "# more conversion: encode categorical variable to be numerical.\ncate_cols = train.select_dtypes(include='category').columns.tolist()\nprint(cate_cols)\nfor c in cate_cols:\n    print(train[c].value_counts())\n    print(\"\")\n#from sklearn.preprocessing import LabelEncoder\n#le = LabelEncoder()\n\n#for col in cate_cols:\n#    print(\"Processing\",col)\n#    train[col] = le.fit_transform(train[col])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2bb804844a698b52d6517625bde04883802487e3"
      },
      "cell_type": "markdown",
      "source": "Seems that the following variables would require further cleanup:\n* SmartScreen (e.g. \"Off\", \"OFF\" and \"off\" are deemed to be different)\n* Census_ChassisTypeName (\"UNKNOWN\" vs \"Unknown\")\n* (I personally have concerns for \"UNKNOWN\" and \"Unspecified\" in *Census_PrimaryDiskTypeName*, but not processed it now)"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "2e8f6c9c7f6b744bd031162c48c70a5152b90221"
      },
      "cell_type": "code",
      "source": "# more cleanup on the categorical data before moving on\ntrans_dict = {\n    'off': 'Off', '&#x02;': '2', '&#x01;': '1', 'on': 'On', 'requireadmin': 'RequireAdmin', 'OFF': 'Off', \n    'Promt': 'Prompt', 'requireAdmin': 'RequireAdmin', 'prompt': 'Prompt', 'warn': 'Warn', \n    '00000000': '0', '&#x03;': '3', np.nan: 'NotExist'\n}\ntrain.replace({'SmartScreen': trans_dict}, inplace=True)\n\ntrans_dict = {\"HandHeld\":\"Handheld\",\"UNKNOWN\":\"Unknown\",np.nan:\"NoExist\"}\ntrain.replace({'Census_ChassisTypeName': trans_dict}, inplace=True)\nprint(train['SmartScreen'].value_counts())\nprint(\"\")\nprint(train['Census_ChassisTypeName'].value_counts())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a1f53b4f4dbc468bcb559a48facb43d0c975c104"
      },
      "cell_type": "code",
      "source": "train['SmartScreen'] = train['SmartScreen'].astype('category')\ntrain['Census_ChassisTypeName'] = train['Census_ChassisTypeName'].astype('category')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "405a80991cf51d1f99559cea66b57baf434e9692"
      },
      "cell_type": "code",
      "source": "cate_cols_orig = train[cate_cols] # save a copy\ntrain[cate_cols] = train[cate_cols].apply(lambda x: x.cat.codes)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "638ea96c7d0d7c09fc218002ec80b93bc2b8039c"
      },
      "cell_type": "markdown",
      "source": "Another concern naturally arises: is it possible that the data contains duplicate machine IDs to capture the same machine at different times? A duplicate check on ID is necessary.\n\n# Duplicate check"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5a8698b6ab7a4e4f20b09c5f9044c2e9f8b0541f"
      },
      "cell_type": "code",
      "source": "# identify duplicate rows in the original dataframe\ncount = 0\nfor index, row in ID_col.duplicated().items():\n    if row is True:\n        print(index, row)\n        count += 1\nprint(\"There are\",count,\"duplicated records in total.\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "393d1a8e7f1d6954d7cd2f38834a22e5708e0a2a"
      },
      "cell_type": "markdown",
      "source": "Looks like we are lucky enough - no duplicate exists, every row accounts for an entirely new machine.\n\nBefore performing any feature engineering, let's see if we can make sense of each given variable. (Looks like explicit time is not given, but can be inferred from some features as suggested by other kernels)\n# Visualization\n\n## Correlation between variables check\n\nInspired by [this notebook](https://www.kaggle.com/jiegeng94/everyone-do-this-at-the-beginning), we might be able to eliminate some features from the very beginning."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bce0fa6d83f53e7f8ab500856af5ee48c3420365"
      },
      "cell_type": "code",
      "source": "cols = train.columns.tolist()\nprint(len(cols))\nco_cols = cols[:10]\nfor c in co_cols:\n    print(\"Column name:\",c,\", data type:\",train[c].dtypes)\nco_cols.append('HasDetections')\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10,10))\nsns.heatmap(train[co_cols].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dd30ddb0896166a45f16cc062433055f6abff09b",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# plot\nf, axes = plt.subplots(2, 5, figsize=(24, 10), sharex=False)\ncount = 0\nfor row in range(2):\n    for col in range(5):\n        sns.distplot(train[np.isfinite(train[co_cols[count]])][co_cols[count]].values, color=\"skyblue\", ax=axes[row, col]).set_title(co_cols[count])\n        count += 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9bf476b0880df17b7033dbe5b2a33a337ade4b01"
      },
      "cell_type": "code",
      "source": "print(train.groupby('RtpStateBitfield').size())\nprint(\"Note: number of NANs:\",train['RtpStateBitfield'].isnull().sum())\nprint(\"\")\nprint(train.groupby('IsSxsPassiveMode').size())\nprint(\"Note: number of NANs:\",train['IsSxsPassiveMode'].isnull().sum())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "61e61f00c7e27370fcf3c6cf4ccb0bc536d62004"
      },
      "cell_type": "code",
      "source": "# a little bit visualization here\nsns.distplot(train[np.isfinite(train['RtpStateBitfield'])]['RtpStateBitfield'].values).set_title('RtpStateBitfield');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d8db36214dd71965e5493881d775ebf8d8d0d3fd"
      },
      "cell_type": "code",
      "source": "def setCountOnTopOfBar(ax):\n    for index in range(len(ax.axes[0])):\n        for p in ax.axes[0][index].patches:\n            height = p.get_height()\n            ax.axes[0][index].text(p.get_x()+p.get_width()/2.,\n                    height + 3,\n                    '{:1.2f}'.format(height),\n                    ha=\"center\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3debebc5968f03de291da88f0d3bfc732221ea9c"
      },
      "cell_type": "code",
      "source": "from matplotlib.pyplot import show\n\nsns.set(style=\"darkgrid\")\n\nax = sns.catplot(x=\"IsSxsPassiveMode\", col=\"HasDetections\",\n                 data=train, kind=\"count\",\n                 height=6, aspect=1.5)\nsetCountOnTopOfBar(ax)\nshow()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4def8a44b8c5563529aacd3be0fce8bbf5b0d58e"
      },
      "cell_type": "markdown",
      "source": "*RtpStateBitfield* and *IsSxsPassiveMode* are correlated - remove *IsSxsPassiveMode* since it's less correlated with the response variable. (Note that they are both really skewed as well)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3926b01c473daf54d9f96b25fffa78e98e926a73"
      },
      "cell_type": "code",
      "source": "co_cols = cols[10:20]\nfor c in co_cols:\n    print(\"Column name:\",c,\", data type:\",train[c].dtypes)\nco_cols.append('HasDetections')\n\nplt.figure(figsize=(10,10))\nsns.heatmap(train[co_cols].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "02d800d78ad2f415f88a578e13bfadc9551e7f53"
      },
      "cell_type": "code",
      "source": "# plot\nf, axes = plt.subplots(2, 5, figsize=(24, 10), sharex=False)\ncount = 0\nfor row in range(2):\n    for col in range(5):\n        sns.distplot(train[np.isfinite(train[co_cols[count]])][co_cols[count]].values, color=\"skyblue\", ax=axes[row, col]).set_title(co_cols[count])\n        count += 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d8c98e7c2233c72eb16e4335afedf8c998818c3c"
      },
      "cell_type": "code",
      "source": "print(train.groupby('Platform').size())\nprint(\"Note: number of NANs:\",train['Platform'].isnull().sum())\nprint(\"\")\nprint(train.groupby('OsVer').size())\nprint(\"Note: number of NANs:\",train['OsVer'].isnull().sum())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "04efeb5ab18b8528f6be2e4f71b4013b17cdeacc"
      },
      "cell_type": "code",
      "source": "# a little bit visualization here\nsns.countplot(train['Platform'],palette=\"Set3\").set_title('Platform')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "40d40e1a6870543ab6c75e7b264e00b837eb613c"
      },
      "cell_type": "code",
      "source": "# a little bit visualization here\nsns.distplot(train[np.isfinite(train['OsVer'])]['OsVer'].values,kde=False).set_title('OsVer');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "14aa324cb73bbd96d0c2ad32a1fcff5c8eb99642"
      },
      "cell_type": "code",
      "source": "print(cate_cols_orig['Platform'].cat.categories)\nprint(cate_cols_orig['OsVer'].cat.categories)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b86a2913f3091847452763cb02f04cc29b10650b"
      },
      "cell_type": "markdown",
      "source": "*Platform* and *OSVer* are correlated - remove *Platform* since it's less correlated with the response variable.\n\nNote: in [this notebook](https://www.kaggle.com/jiegeng94/everyone-do-this-at-the-beginning) both variables are eliminated due to skewness. I personally **DON'T** like the idea of dropping features purely due to skewness. We could have done some tricks like log transformation described [here](https://becominghuman.ai/how-to-deal-with-skewed-dataset-in-machine-learning-afd2928011cc). So skewness won't be a metric to use to eliminate variables."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ac4f70a285554f81b297c4520a6c112bafc292b2"
      },
      "cell_type": "code",
      "source": "co_cols = cols[20:30]\nfor c in co_cols:\n    print(\"Column name:\",c,\", data type:\",train[c].dtypes)\nco_cols.append('HasDetections')\n\nplt.figure(figsize=(10,10))\nsns.heatmap(train[co_cols].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ad11d745a082f805a319121db24649575a790456"
      },
      "cell_type": "code",
      "source": "# plot\nf, axes = plt.subplots(2, 5, figsize=(24, 10), sharex=False)\ncount = 0\nfor row in range(2):\n    for col in range(5):\n        sns.distplot(train[np.isfinite(train[co_cols[count]])][co_cols[count]].values, color=\"skyblue\", ax=axes[row, col]).set_title(co_cols[count])\n        count += 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b90f2d7d0b98b63c39e110c98a05129647379b4d"
      },
      "cell_type": "code",
      "source": "print(train.groupby('OsSuite').size())\nprint(\"Note: number of NANs:\",train['OsSuite'].isnull().sum())\nprint(\"\")\nprint(train.groupby('SkuEdition').size())\nprint(\"Note: number of NANs:\",train['SkuEdition'].isnull().sum())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3b79e7b5c1deea49ab4b2ff159ce5f5ff20fbfb4"
      },
      "cell_type": "code",
      "source": "# a little bit visualization here\nsns.countplot(train['OsSuite'],palette=\"Set2\").set_title('OsSuite')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bebc8327033987225826b2251dca397955e91240"
      },
      "cell_type": "code",
      "source": "sns.countplot(train['SkuEdition'],palette=\"Set3\").set_title('SkuEdition')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2db34a2bcb1e013f7af87bd0b3a642aa57d38f35"
      },
      "cell_type": "markdown",
      "source": "*OsSuite* and *SkuEdition* are correlated - remove *SkuEdition* since it's less correlated with the response variable (Or, should we? Both are categorical variables and now are represented in their numerical encodings. Is this the correct way to measure their correlations?)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a36f8792db8bd79c288bd2179b023c3c9d96a48c"
      },
      "cell_type": "code",
      "source": "co_cols = cols[30:40]\nfor c in co_cols:\n    print(\"Column name:\",c,\", data type:\",train[c].dtypes)\nco_cols.append('HasDetections')\n\nplt.figure(figsize=(10,10))\nsns.heatmap(train[co_cols].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "53bb919743b47c4c0b27935fe8c5490645fcaeb9"
      },
      "cell_type": "code",
      "source": "# plot\nf, axes = plt.subplots(2, 5, figsize=(24, 10), sharex=False)\ncount = 0\nfor row in range(2):\n    for col in range(5):\n        sns.distplot(train[np.isfinite(train[co_cols[count]])][co_cols[count]].values, color=\"skyblue\", ax=axes[row, col]).set_title(co_cols[count])\n        count += 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "78870a7e2cadf89357bf3a0df689c4b5686844fe"
      },
      "cell_type": "code",
      "source": "print(train.groupby('Census_ProcessorManufacturerIdentifier').size())\nprint(\"Note: number of NANs:\",train['Census_ProcessorManufacturerIdentifier'].isnull().sum())\nprint(\"\")\nprint(train.groupby('Census_ProcessorModelIdentifier').size())\nprint(\"Note: number of NANs:\",train['Census_ProcessorModelIdentifier'].isnull().sum())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e9f9dc202e9cbcd06c685867c82cb8ac7aa8bc3f"
      },
      "cell_type": "code",
      "source": "# a little bit visualization here\nsns.countplot(train['Census_ProcessorManufacturerIdentifier'],palette=\"Set2\").set_title('Census_ProcessorManufacturerIdentifier')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "80d4bf66018ce0e0a783afa4f984ee34c1fdcdf6"
      },
      "cell_type": "code",
      "source": "sns.distplot(train[np.isfinite(train['Census_ProcessorModelIdentifier'])]['Census_ProcessorModelIdentifier'].values,kde=False).set_title('Census_ProcessorModelIdentifier');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bf6b724d3941400b6fecd94ee5f31c923fb560b2"
      },
      "cell_type": "markdown",
      "source": "*Census_ProcessorManufacturerIdentifier* and *Census_ProcessorModelIdentifier* are correlated - remove *Census_ProcessorManufacturerIdentifier* since it's less correlated with the response variable (plus in a much finer grain)."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7f6e823e43cf5d5f3bee97cba81c3dbca8d018dc",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "co_cols = cols[40:50]\nfor c in co_cols:\n    print(\"Column name:\",c,\", data type:\",train[c].dtypes)\nco_cols.append('HasDetections')\n\nplt.figure(figsize=(10,10))\nsns.heatmap(train[co_cols].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "527f1655300804f17ca96c92b41d1ebe1e7fc71a"
      },
      "cell_type": "code",
      "source": "# plot\nf, axes = plt.subplots(2, 5, figsize=(24, 10), sharex=False)\ncount = 0\nfor row in range(2):\n    for col in range(5):\n        sns.distplot(train[np.isfinite(train[co_cols[count]])][co_cols[count]].values, color=\"skyblue\", ax=axes[row, col]).set_title(co_cols[count])\n        count += 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "353a259fd54e7bd3b9a4d37aa51db93a85073107"
      },
      "cell_type": "markdown",
      "source": "*Census_InternalPrimaryDisplayResolutionHorizontal* and *Census_InternalPrimaryDisplayResolutionVertical* are correlated - remove *Census_InternalPrimaryDisplayResolutionVertical* since it's less correlated with the response variable"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1ee7a0a9873fbd893e106a4117f259d1c440ac19"
      },
      "cell_type": "code",
      "source": "co_cols = cols[50:60]\nfor c in co_cols:\n    print(\"Column name:\",c,\", data type:\",train[c].dtypes)\nco_cols.append('HasDetections')\n\nplt.figure(figsize=(10,10))\nsns.heatmap(train[co_cols].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bc82bba85d1e5fb47ac471f93872af975bcd93cc"
      },
      "cell_type": "code",
      "source": "# plot\nf, axes = plt.subplots(2, 5, figsize=(24, 10), sharex=False)\ncount = 0\nfor row in range(2):\n    for col in range(5):\n        sns.distplot(train[np.isfinite(train[co_cols[count]])][co_cols[count]].values, color=\"skyblue\", ax=axes[row, col]).set_title(co_cols[count])\n        count += 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a9645f836678e679f5c6dddc774035e5b7b99e75"
      },
      "cell_type": "code",
      "source": "print(train['Census_OSEdition'].cat.categories)\nprint(train['Census_OSSkuName'].cat.categories)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "677dc30b7c1dbb29d2482bf1334ca3b855495db6"
      },
      "cell_type": "markdown",
      "source": "* *Census_OSEdition* and *Census_OSSkuName* are the same... OR ARE THEY?\n* *Census_OSInstallLanguageIdentifier* and *Census_OSUILocaleIdentifier* are basically the same."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ffd64307de6286c24223859d15706b84c15d4c28"
      },
      "cell_type": "code",
      "source": "co_cols = cols[60:70]\nfor c in co_cols:\n    print(\"Column name:\",c,\", data type:\",train[c].dtypes)\nco_cols.append('HasDetections')\n\nplt.figure(figsize=(10,10))\nsns.heatmap(train[co_cols].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "296f827084ac9785e6d6c13e90ed69c42b58c3e4"
      },
      "cell_type": "code",
      "source": "# plot\nf, axes = plt.subplots(2, 5, figsize=(24, 10), sharex=False)\ncount = 0\nfor row in range(2):\n    for col in range(5):\n        sns.distplot(train[np.isfinite(train[co_cols[count]])][co_cols[count]].values, color=\"skyblue\", ax=axes[row, col]).set_title(co_cols[count])\n        count += 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a1c4a19d62a5db0813f8957dec915c5a7cb6219c"
      },
      "cell_type": "markdown",
      "source": "Things are looking good here for the 10 variables."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bba8f4811495cc5e829f88f347b0cd0f42f975d6"
      },
      "cell_type": "code",
      "source": "co_cols = cols[70:]\nfor c in co_cols:\n    print(\"Column name:\",c,\", data type:\",train[c].dtypes)\n\nplt.figure(figsize=(10,10))\nsns.heatmap(train[co_cols].corr(), cmap='RdBu_r', annot=True, center=0.0)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "405ade82387875e6f206bc3428a31fdef8730c97"
      },
      "cell_type": "code",
      "source": "# plot\nf, axes = plt.subplots(1, 5, figsize=(24, 10), sharex=False)\ncount = 0\nfor row in range(1):\n    for col in range(5):\n        sns.distplot(train[np.isfinite(train[co_cols[count]])][co_cols[count]].values, color=\"skyblue\", ax=axes[row, col]).set_title(co_cols[count])\n        count += 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6842337413a51fbbac8fc71b5370cb3538380ad6"
      },
      "cell_type": "markdown",
      "source": "Seems to be no more variable to reduce here as well."
    },
    {
      "metadata": {
        "_uuid": "5a3a9c78f073066718d54c510ba34dcd8246eacb"
      },
      "cell_type": "markdown",
      "source": "## ProductName"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c380d71d292cef6f6dd606e5099156eab5241b82"
      },
      "cell_type": "code",
      "source": "def setCountOnTopOfBar(ax):\n    for index in range(len(ax.axes[0])):\n        for p in ax.axes[0][index].patches:\n            height = p.get_height()\n            ax.axes[0][index].text(p.get_x()+p.get_width()/2.,\n                    height + 3,\n                    '{:1.2f}'.format(height),\n                    ha=\"center\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2923d476e410a9c67e0f43ebfecb085a3fb5da98",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "from matplotlib.pyplot import show\n\nsns.set(style=\"darkgrid\")\nax = sns.catplot(x=\"ProductName\", col=\"HasDetections\",\n                 data=train, kind=\"count\",\n                 height=6, aspect=1.5)\nsetCountOnTopOfBar(ax)\nshow()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0709a635fd1248a5f51b1850523b1e67d3364c1f"
      },
      "cell_type": "markdown",
      "source": "Looks like ProductName is not an informative feature itself... both groups are dominated by *win8defender*. The distributions of other versions are about the same.\n\n## EngineVersion\n\nA preliminary check shows that there are 70 engine versions in total. For the sake of time I will just visualize the top 5 here."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "733ded50703d9d4c019a910e388de89e228a2e07"
      },
      "cell_type": "code",
      "source": "noDTop5 = train[(train['HasDetections'] == 0)].groupby(['EngineVersion']).size().sort_values(ascending=False)[:5]\nprint(noDTop5)\ntop5indexes = noDTop5.keys().tolist()\nprint(\"\")\nDTop5 = train[(train['HasDetections'] == 1)].groupby(['EngineVersion']).size()\nDTop5sliced = DTop5[DTop5.index.isin(top5indexes)].reindex(top5indexes)\nprint(DTop5sliced)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bf6bd4e84df50becb0799c2cde34987f977138df"
      },
      "cell_type": "code",
      "source": "# code: https://stackoverflow.com/questions/30228069/how-to-display-the-value-of-the-bar-on-each-bar-with-pyplot-barh\n# code: https://matplotlib.org/gallery/units/bar_unit_demo.html\nN = len(top5indexes)\nfig, ax = plt.subplots(figsize=(20,10))\n\nind = np.arange(N)    # the x locations for the groups\nwidth = 0.35         # the width of the bars\np1 = ax.bar(ind, noDTop5.tolist(), width, color='r')\np2 = ax.bar(ind + width, DTop5sliced.tolist(), width, color='y')\n\nax.set_title('EngineVersion (top 5 measured by not affected computers)')\nax.set_xticks(ind + width / 2)\nax.set_xticklabels(top5indexes)\n\nax.legend((p1[0], p2[0]), ('HasDetections = 0', 'HasDetections = 1'))\nax.autoscale_view()\n\ndef autolabel(rects):\n    \"\"\"\n    Attach a text label above each bar displaying its height\n    \"\"\"\n    for rect in rects:\n        height = rect.get_height()\n        ax.text(rect.get_x() + rect.get_width()/2., 1*height,\n                '%d' % int(height),\n                ha='center', va='bottom')\n\nautolabel(p1)\nautolabel(p2)\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a7096949444cf41b81a1f6958f5cbd06e3688139"
      },
      "cell_type": "markdown",
      "source": "Would there be a significant difference if we count the top 5 engine versions from the attacked computers?"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5311333b6a1029a1256a18a702ef3782de800a57"
      },
      "cell_type": "code",
      "source": "DTop5 = train[(train['HasDetections'] == 1)].groupby(['EngineVersion']).size().sort_values(ascending=False)[:5]\nprint(DTop5)\ntop5indexes = DTop5.keys().tolist()\nprint(\"\")\nnoDTop5 = train[(train['HasDetections'] == 0)].groupby(['EngineVersion']).size()\nnoDTop5sliced = noDTop5[noDTop5.index.isin(top5indexes)].reindex(top5indexes)\nprint(noDTop5sliced)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d5a63ed60b177ca960a981f38e10ac7ae6240d8c"
      },
      "cell_type": "code",
      "source": "# code: https://stackoverflow.com/questions/30228069/how-to-display-the-value-of-the-bar-on-each-bar-with-pyplot-barh\n# code: https://matplotlib.org/gallery/units/bar_unit_demo.html\nN = len(top5indexes)\nfig, ax = plt.subplots(figsize=(20,10))\n\nind = np.arange(N)    # the x locations for the groups\nwidth = 0.35         # the width of the bars\np1 = ax.bar(ind, noDTop5sliced.tolist(), width, color='r')\np2 = ax.bar(ind + width, DTop5.tolist(), width, color='y')\n\nax.set_title('EngineVersion (top 5 measured by affected computers)')\nax.set_xticks(ind + width / 2)\nax.set_xticklabels(top5indexes)\n\nax.legend((p1[0], p2[0]), ('HasDetections = 0', 'HasDetections = 1'))\nax.autoscale_view()\n\ndef autolabel(rects):\n    \"\"\"\n    Attach a text label above each bar displaying its height\n    \"\"\"\n    for rect in rects:\n        height = rect.get_height()\n        ax.text(rect.get_x() + rect.get_width()/2., 1*height,\n                '%d' % int(height),\n                ha='center', va='bottom')\n\nautolabel(p1)\nautolabel(p2)\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e3e698a40d4d12a4c40fceb2f8942d74a98dd91e"
      },
      "cell_type": "markdown",
      "source": "So we do have a discrepency here: both 1.1.15100.1, 1.1.15200.1, and 1.1.15000.2 are popular versions among the safe and affected instances, but we have more unaffected computers under version 1.1.14901.4 and 1.1.14800.3, and more affected computers under version So we do have a discrepency here: both 1.1.15100.1, 1.1.15200.1, 1.1.15000.2 and 1.1.14901.4 are popular versions among the safe and affected instances, but we have more unaffected computers under version 1.1.14800.3, and more affected computers under version1.1.14600.4. Might be interesting if we are able to map this to actual time.\n\n## AppVersion"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d0c399831e0a159d05ecf28194c39284a28accde"
      },
      "cell_type": "code",
      "source": "fig, ax = plt.subplots(2,1,figsize=(16,10),squeeze=False)\nsns.countplot(train[train['HasDetections'] == 0]['AppVersion'], ax=ax[0,0])\nsns.countplot(train[train['HasDetections'] == 1]['AppVersion'], ax=ax[1,0])\nax[0,0].set_xticklabels(ax[0,0].get_xticklabels(), rotation=90, ha=\"right\")\nax[1,0].set_xticklabels(ax[1,0].get_xticklabels(), rotation=90, ha=\"right\")\nplt.tight_layout()\nfig.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bf4a695515b8073059e976a3a92ffc1cfa9b8333"
      },
      "cell_type": "markdown",
      "source": "The distribution of AppVersion between infected and normal computers are about the same. How about AvSigVersion?\n\n## AvSigVersion\n\nCode for visualization is available below; however, since there are 8531 records in total, it's really hard to visualize the end result. Looks like it's a even finer-grain defined feature, so might be useful if we decide to map to concrete time."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a259715aef919ee6e2d5d3dffdb1cf4da3fcc550"
      },
      "cell_type": "code",
      "source": "avsigcheck = train[(train['HasDetections'] == 0)].groupby(['AvSigVersion']).size().sort_values(ascending=False)\nprint(avsigcheck.size)\n#fig, ax = plt.subplots(2,1,figsize=(16,10),squeeze=False)\n#sns.countplot(train[train['HasDetections'] == 0]['AvSigVersion'], ax=ax[0,0])\n#sns.countplot(train[train['HasDetections'] == 1]['AvSigVersion'], ax=ax[1,0])\n#ax[0,0].set_xticklabels(ax[0,0].get_xticklabels(), rotation=90, ha=\"right\")\n#ax[1,0].set_xticklabels(ax[1,0].get_xticklabels(), rotation=90, ha=\"right\")\n#plt.tight_layout()\n#fig.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9d65f7d7c489a9d4f399ba6e2ca77c7d2d0997a6"
      },
      "cell_type": "markdown",
      "source": "## IsBeta\n\nA quick check below shows that **IsBeta** is also dominated by 0 (that is, most of the machines are not Beta version). It's a highly skewed distribution for sure. As for the 67 machines that is beta, how many of them are infected (or not)?"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5461ad0890bf066a6f42abb94b060a227f8058b1"
      },
      "cell_type": "code",
      "source": "isBetaSeries = train.groupby(['IsBeta']).size().sort_values(ascending=False)\nprint(isBetaSeries)\nsns.countplot(train['IsBeta'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a4df50e8ae489826bc863f545f13fe1af994b3a8"
      },
      "cell_type": "code",
      "source": "isBetaSeries = train[train['IsBeta'] == 1].groupby(['HasDetections']).size().sort_values(ascending=False)\nprint(isBetaSeries)\nsns.countplot(train[train['IsBeta'] == 1]['HasDetections'],palette=\"Set3\").set_title('IsBeta')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4d447725d7bf7c8de68cc6ae5ae1884ac4ec66ea"
      },
      "cell_type": "markdown",
      "source": "So even if a machine has beta version, its likelihood of getting infected based on the data seems to be 50/50. \n\nLet's quickly check some variables that deem to be \"NA\" in the data description and see if we can make sense of them.\n\n## \"NA\" variables???\n\nThe following 19 variables have no description:\n\n* RtpStateBitfield\n* IsSxsPassiveMode\n* AVProductsInstalled\n* AVProductsEnabled\n* IeVerIdentifier\n* Census_OEMNameIdentifier\n* Census_OEMModelIdentifier\n* Census_ProcessorManufacturerIdentifier\n* Census_ProcessorModelIdentifier\n* Census_InternalBatteryType\n* Census_InternalBatteryNumberOfCharges\n* Census_OSInstallLanguageIdentifier\n* Census_OSUILocaleIdentifier\n* Census_IsFlightingInternal\n* Census_ThresholdOptIn\n* Census_FirmwareManufacturerIdentifier\n* Census_FirmwareVersionIdentifier\n* Census_IsWIMBootEnabled\n* Wdft_RegionIdentifier"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ac9bf5f520bf70859006fbc3f7883b55430098ba"
      },
      "cell_type": "code",
      "source": "RtpStateBitfieldSeries = train.groupby(['RtpStateBitfield']).size().sort_values(ascending=False)\nprint(RtpStateBitfieldSeries)\nprint(\"Note: number of NANs:\",train['RtpStateBitfield'].isnull().sum())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fa6464daf8b983e651c28c6d6cb467f49fe09780"
      },
      "cell_type": "code",
      "source": "# looks like 35.0 is an outlier, but can't say for sure now\nsns.distplot(train[np.isfinite(train['RtpStateBitfield'])]['RtpStateBitfield'].values).set_title('RtpStateBitfield');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bab13dd8593881194b61e5e680ec7c887c6126df"
      },
      "cell_type": "code",
      "source": "IsSxsPassiveModeSeries = train.groupby(['IsSxsPassiveMode']).size().sort_values(ascending=False)\nprint(IsSxsPassiveModeSeries)\nprint(\"Note: number of NANs:\",train['IsSxsPassiveMode'].isnull().sum())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0d3faa3c892b1b5dcb94e2469f87a5671401be8e"
      },
      "cell_type": "code",
      "source": "ax = sns.catplot(x=\"IsSxsPassiveMode\", col=\"HasDetections\",\n                 data=train, kind=\"count\",\n                 height=6, aspect=1.5)\ncountOverCountPlot(ax)\nshow()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c354089a014bf1f785010327a532337dbab50ca8"
      },
      "cell_type": "code",
      "source": "AVProductsInstalledSeries = train.groupby(['AVProductsInstalled']).size().sort_values(ascending=False)\nprint(AVProductsInstalledSeries)\nprint(\"Note: number of NANs:\",train['AVProductsInstalled'].isnull().sum())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a2e5e03dfefedb1a9e236151fc770b6af3f9bf1"
      },
      "cell_type": "code",
      "source": "sns.distplot(train[np.isfinite(train['AVProductsInstalled'])]['AVProductsInstalled'].values, kde=False).set_title('AVProductsInstalled');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b1c5af8be2ef535b9e17d1897723ad380baad82d"
      },
      "cell_type": "code",
      "source": "AVProductsEnabledSeries = train.groupby(['AVProductsEnabled']).size().sort_values(ascending=False)\nprint(AVProductsEnabledSeries)\nprint(\"Size:\",AVProductsEnabledSeries.shape)\nprint(\"Note: number of NANs:\",train['AVProductsEnabled'].isnull().sum())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2a7d3e757cc64af5101fe8fe1ffc9b21b6e79fb9"
      },
      "cell_type": "code",
      "source": "sns.distplot(train[np.isfinite(train['AVProductsEnabled'])]['AVProductsEnabled'].values, kde=False).set_title('AVProductsEnabled');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2192b863269c44230bd33801e24b6aa00e03a456"
      },
      "cell_type": "code",
      "source": "IeVerIdentifierSeries = train.groupby(['IeVerIdentifier']).size().sort_values(ascending=False)\nprint(IeVerIdentifierSeries.head())\nprint(\"Size:\",IeVerIdentifierSeries.shape)\nprint(\"Note: number of NANs:\",train['IeVerIdentifier'].isnull().sum())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "22db853e9b1989ff8dd3f9cce2f96f405e9179bb"
      },
      "cell_type": "code",
      "source": "sns.distplot(train[np.isfinite(train['IeVerIdentifier'])]['IeVerIdentifier'].values, kde=False).set_title('IeVerIdentifier');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a6bea4c97b5f16858e48706f1bb29405e4f9d317"
      },
      "cell_type": "code",
      "source": "ax = sns.catplot(x=\"IeVerIdentifier\", col=\"HasDetections\",\n                 data=train[np.isfinite(train['IeVerIdentifier'])], kind=\"count\",\n                 height=6, aspect=1.5)\nsetCountOnTopOfBar(ax)\nshow()",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}