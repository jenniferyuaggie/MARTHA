{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "light-gbm-on-stratified-k-folds-malwares.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "_uuid": "4499bd88595e1d6d3f19f8ffe3dcf92b7306e30a",
        "id": "W2mLo1Cb6qw7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Inspired by \n",
        "\n",
        "* Theo Viel's kernel (https://www.kaggle.com/theoviel/load-the-totality-of-the-data)\n",
        "* Vladislav Bogorod's Kernel https://www.kaggle.com/bogorodvo/lightgbm-baseline-model-using-sparse-matrix\n",
        "\n",
        "I am using Light GBM Classifier on a Stratified K Fold Technique."
      ]
    },
    {
      "metadata": {
        "id": "KOGf1dTE6sR4",
        "colab_type": "code",
        "outputId": "8ee1a9cb-3e2c-40b1-f732-9287a3afbb21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# load the data from Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "mqeJQIOt6qw-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "import pickle\n",
        "\n",
        "import xgboost as xgb\n",
        "from scipy.sparse import vstack, csr_matrix, save_npz, load_npz\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn import feature_selection\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.utils import check_array\n",
        "from scipy import sparse\n",
        "\n",
        "# Scalers\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "import gc\n",
        "gc.enable()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "qLJ8Mf8R6qxF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dtypes = {\n",
        "        'MachineIdentifier':                                    'category',\n",
        "        'ProductName':                                          'category',\n",
        "        'EngineVersion':                                        'category',\n",
        "        'AppVersion':                                           'category',\n",
        "        'AvSigVersion':                                         'category',\n",
        "        'IsBeta':                                               'int8',\n",
        "        'RtpStateBitfield':                                     'float16',\n",
        "        'IsSxsPassiveMode':                                     'int8',\n",
        "        'DefaultBrowsersIdentifier':                            'float16',\n",
        "        'AVProductStatesIdentifier':                            'float32',\n",
        "        'AVProductsInstalled':                                  'float16',\n",
        "        'AVProductsEnabled':                                    'float16',\n",
        "        'HasTpm':                                               'int8',\n",
        "        'CountryIdentifier':                                    'int16',\n",
        "        'CityIdentifier':                                       'float32',\n",
        "        'OrganizationIdentifier':                               'float16',\n",
        "        'GeoNameIdentifier':                                    'float16',\n",
        "        'LocaleEnglishNameIdentifier':                          'int8',\n",
        "        'Platform':                                             'category',\n",
        "        'Processor':                                            'category',\n",
        "        'OsVer':                                                'category',\n",
        "        'OsBuild':                                              'int16',\n",
        "        'OsSuite':                                              'int16',\n",
        "        'OsPlatformSubRelease':                                 'category',\n",
        "        'OsBuildLab':                                           'category',\n",
        "        'SkuEdition':                                           'category',\n",
        "        'IsProtected':                                          'float16',\n",
        "        'AutoSampleOptIn':                                      'int8',\n",
        "        'PuaMode':                                              'category',\n",
        "        'SMode':                                                'float16',\n",
        "        'IeVerIdentifier':                                      'float16',\n",
        "        'SmartScreen':                                          'category',\n",
        "        'Firewall':                                             'float16',\n",
        "        'UacLuaenable':                                         'float32',\n",
        "        'Census_MDC2FormFactor':                                'category',\n",
        "        'Census_DeviceFamily':                                  'category',\n",
        "        'Census_OEMNameIdentifier':                             'float16',\n",
        "        'Census_OEMModelIdentifier':                            'float32',\n",
        "        'Census_ProcessorCoreCount':                            'float16',\n",
        "        'Census_ProcessorManufacturerIdentifier':               'float16',\n",
        "        'Census_ProcessorModelIdentifier':                      'float16',\n",
        "        'Census_ProcessorClass':                                'category',\n",
        "        'Census_PrimaryDiskTotalCapacity':                      'float32',\n",
        "        'Census_PrimaryDiskTypeName':                           'category',\n",
        "        'Census_SystemVolumeTotalCapacity':                     'float32',\n",
        "        'Census_HasOpticalDiskDrive':                           'int8',\n",
        "        'Census_TotalPhysicalRAM':                              'float32',\n",
        "        'Census_ChassisTypeName':                               'category',\n",
        "        'Census_InternalPrimaryDiagonalDisplaySizeInInches':    'float16',\n",
        "        'Census_InternalPrimaryDisplayResolutionHorizontal':    'float16',\n",
        "        'Census_InternalPrimaryDisplayResolutionVertical':      'float16',\n",
        "        'Census_PowerPlatformRoleName':                         'category',\n",
        "        'Census_InternalBatteryType':                           'category',\n",
        "        'Census_InternalBatteryNumberOfCharges':                'float32',\n",
        "        'Census_OSVersion':                                     'category',\n",
        "        'Census_OSArchitecture':                                'category',\n",
        "        'Census_OSBranch':                                      'category',\n",
        "        'Census_OSBuildNumber':                                 'int16',\n",
        "        'Census_OSBuildRevision':                               'int32',\n",
        "        'Census_OSEdition':                                     'category',\n",
        "        'Census_OSSkuName':                                     'category',\n",
        "        'Census_OSInstallTypeName':                             'category',\n",
        "        'Census_OSInstallLanguageIdentifier':                   'float16',\n",
        "        'Census_OSUILocaleIdentifier':                          'int16',\n",
        "        'Census_OSWUAutoUpdateOptionsName':                     'category',\n",
        "        'Census_IsPortableOperatingSystem':                     'int8',\n",
        "        'Census_GenuineStateName':                              'category',\n",
        "        'Census_ActivationChannel':                             'category',\n",
        "        'Census_IsFlightingInternal':                           'float16',\n",
        "        'Census_IsFlightsDisabled':                             'float16',\n",
        "        'Census_FlightRing':                                    'category',\n",
        "        'Census_ThresholdOptIn':                                'float16',\n",
        "        'Census_FirmwareManufacturerIdentifier':                'float16',\n",
        "        'Census_FirmwareVersionIdentifier':                     'float32',\n",
        "        'Census_IsSecureBootEnabled':                           'int8',\n",
        "        'Census_IsWIMBootEnabled':                              'float16',\n",
        "        'Census_IsVirtualDevice':                               'float16',\n",
        "        'Census_IsTouchEnabled':                                'int8',\n",
        "        'Census_IsPenCapable':                                  'int8',\n",
        "        'Census_IsAlwaysOnAlwaysConnectedCapable':              'float16',\n",
        "        'Wdft_IsGamer':                                         'float16',\n",
        "        'Wdft_RegionIdentifier':                                'float16',\n",
        "        'HasDetections':                                        'int8'\n",
        "        }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6fa2e9202607c4064a584c76c35ba91f7bfd02a5",
        "id": "11mswOuq6qxK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Reduce the memory usage - Inspired by Panchajanya Banerjee\n",
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)    \n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "921caf9cc1b47f49b412cbe8594df56e9d171e22",
        "id": "oSPFSNRx6qxP",
        "colab_type": "code",
        "outputId": "3f48cc10-e86f-4545-af43-a2c468e6bb96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "print('Download Train and Test Data.\\n')\n",
        "train = reduce_mem_usage(pd.read_csv('/content/gdrive/My Drive/Coding experiment/MARTHA/data/train.csv', dtype=dtypes, low_memory=True))\n",
        "train['MachineIdentifier'] = train.index.astype('uint32')\n",
        "test  = reduce_mem_usage(pd.read_csv('/content/gdrive/My Drive/Coding experiment/MARTHA/data/test.csv',  dtype=dtypes, low_memory=True))\n",
        "test['MachineIdentifier']  = test.index.astype('uint32')\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download Train and Test Data.\n",
            "\n",
            "Mem. usage decreased to 1673.25 Mb (0.0% reduction)\n",
            "Mem. usage decreased to 1503.79 Mb (0.0% reduction)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "201334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "5106144cbff3286026a6e5dd458752e725c677cb",
        "id": "7iJYy1mM6qxY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Feature Engineering\n",
        "\n",
        "Only run this if you don't have saved the transformed features already."
      ]
    },
    {
      "metadata": {
        "_uuid": "c324b79bd14cbe2caaa39e7fe1cb77854679107d",
        "id": "CZH60qsW6qxa",
        "colab_type": "code",
        "outputId": "85c3ad75-229d-484e-eca6-c9178de7986c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "print('Transform all features to category.\\n')\n",
        "counter = 0\n",
        "\n",
        "for usecol in train.columns.tolist()[1:-1]:\n",
        "\n",
        "    train[usecol] = train[usecol].astype('str')\n",
        "    test[usecol] = test[usecol].astype('str')\n",
        "    \n",
        "    if counter % 5 == 0:\n",
        "       print(\"Transformed\",counter,\"features.\")\n",
        "    #Fit LabelEncoder\n",
        "    le = LabelEncoder().fit(\n",
        "            np.unique(train[usecol].unique().tolist()+\n",
        "                      test[usecol].unique().tolist()))\n",
        "\n",
        "    #At the end 0 will be used for dropped values\n",
        "    train[usecol] = le.transform(train[usecol])+1\n",
        "    test[usecol]  = le.transform(test[usecol])+1\n",
        "\n",
        "    agg_tr = (train\n",
        "              .groupby([usecol])\n",
        "              .aggregate({'MachineIdentifier':'count'})\n",
        "              .reset_index()\n",
        "              .rename({'MachineIdentifier':'Train'}, axis=1))\n",
        "    agg_te = (test\n",
        "              .groupby([usecol])\n",
        "              .aggregate({'MachineIdentifier':'count'})\n",
        "              .reset_index()\n",
        "              .rename({'MachineIdentifier':'Test'}, axis=1))\n",
        "\n",
        "    agg = pd.merge(agg_tr, agg_te, on=usecol, how='outer').replace(np.nan, 0)\n",
        "    #Select values with more than 1000 observations\n",
        "    agg = agg[(agg['Train'] > 1000)].reset_index(drop=True)\n",
        "    agg['Total'] = agg['Train'] + agg['Test']\n",
        "    #Drop unbalanced values\n",
        "    agg = agg[(agg['Train'] / agg['Total'] > 0.2) & (agg['Train'] / agg['Total'] < 0.8)]\n",
        "    agg[usecol+'Copy'] = agg[usecol]\n",
        "\n",
        "    train[usecol] = (pd.merge(train[[usecol]], \n",
        "                              agg[[usecol, usecol+'Copy']], \n",
        "                              on=usecol, how='left')[usecol+'Copy']\n",
        "                     .replace(np.nan, 0).astype('int').astype('category'))\n",
        "\n",
        "    test[usecol]  = (pd.merge(test[[usecol]], \n",
        "                              agg[[usecol, usecol+'Copy']], \n",
        "                              on=usecol, how='left')[usecol+'Copy']\n",
        "                     .replace(np.nan, 0).astype('int').astype('category'))\n",
        "\n",
        "    del le, agg_tr, agg_te, agg, usecol\n",
        "    gc.collect()\n",
        "    \n",
        "    counter += 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Transform all features to category.\n",
            "\n",
            "Transformed 0 features.\n",
            "Transformed 5 features.\n",
            "Transformed 10 features.\n",
            "Transformed 15 features.\n",
            "Transformed 20 features.\n",
            "Transformed 25 features.\n",
            "Transformed 30 features.\n",
            "Transformed 35 features.\n",
            "Transformed 40 features.\n",
            "Transformed 45 features.\n",
            "Transformed 50 features.\n",
            "Transformed 55 features.\n",
            "Transformed 60 features.\n",
            "Transformed 65 features.\n",
            "Transformed 70 features.\n",
            "Transformed 75 features.\n",
            "Transformed 80 features.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I4maN32BRBpM",
        "colab_type": "code",
        "outputId": "19bad30d-d0db-4622-eb8f-872d8d82a629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "y_train = np.array(train['HasDetections'])\n",
        "train_ids = train.index\n",
        "test_ids  = test.index\n",
        "\n",
        "del train['HasDetections'], train['MachineIdentifier'], test['MachineIdentifier']\n",
        "gc.collect()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "4nKXody5CTYr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del train, test\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e3_FRcxiRkqb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Skip the one hot encoding below if the data has already been saved."
      ]
    },
    {
      "metadata": {
        "_uuid": "4d3073ef05ae7965bbce508b4c132535cb230392",
        "id": "JeH4ad636qxg",
        "colab_type": "code",
        "outputId": "99d87fe6-e3a7-4e9c-ffac-82d6a0a08f43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Fit OneHotEncoder\n",
        "ohe = OneHotEncoder(categories='auto', sparse=True, dtype='uint8').fit(train)\n",
        "\n",
        "#Transform data using small groups to reduce memory usage\n",
        "m = 100000\n",
        "train = vstack([ohe.transform(train[i*m:(i+1)*m]) for i in range(train.shape[0] // m + 1)])\n",
        "test  = vstack([ohe.transform(test[i*m:(i+1)*m])  for i in range(test.shape[0] // m +  1)])\n",
        "\n",
        "save_npz('/content/gdrive/My Drive/Coding experiment/MARTHA/train.npz', train, compressed=True)\n",
        "save_npz('/content/gdrive/My Drive/Coding experiment/MARTHA/test.npz',  test,  compressed=True)\n",
        "\n",
        "del ohe, train, test\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2296"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "L6FGSgDcRCmC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = load_npz('/content/gdrive/My Drive/Coding experiment/MARTHA/train.npz')\n",
        "test = load_npz('/content/gdrive/My Drive/Coding experiment/MARTHA/test.npz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bd20eae99788e4dd20d2925ea9a4435a24625ead",
        "id": "OPKzgOD36qxl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now Build the Stratified K Fold Model and generate predictions"
      ]
    },
    {
      "metadata": {
        "_uuid": "0edb559f1265283e2c0ce06528ba0fea295426c0",
        "id": "fvSl9mBH6qxn",
        "colab_type": "code",
        "outputId": "dc51a0c6-b983-4eca-d031-c659b9476dbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "skf.get_n_splits(train_ids, y_train)\n",
        "lgb_test_result_1  = np.zeros(test_ids.shape[0])\n",
        "oof_1= np.zeros(train_ids.shape[0])\n",
        "\n",
        "counter = 0\n",
        "m = 100000\n",
        "\n",
        "print('\\nLightGBM\\n')\n",
        "\n",
        "for train_index, test_index in skf.split(train_ids, y_train):\n",
        "    \n",
        "    print('Fold {}\\n'.format(counter + 1))\n",
        "    \n",
        "    train = load_npz('/content/gdrive/My Drive/Coding experiment/MARTHA/train.npz')\n",
        "    X_fit = vstack([train[train_index[i*m:(i+1)*m]] for i in range(train_index.shape[0] // m + 1)])\n",
        "    X_val = vstack([train[test_index[i*m:(i+1)*m]]  for i in range(test_index.shape[0] //  m + 1)])\n",
        "    X_fit, X_val = csr_matrix(X_fit, dtype='float32'), csr_matrix(X_val, dtype='float32')\n",
        "    y_fit, y_val = y_train[train_index], y_train[test_index]\n",
        "    \n",
        "    \n",
        "    del train\n",
        "    gc.collect()\n",
        "\n",
        "    lgb_model = lgb.LGBMClassifier(max_depth=-1,\n",
        "                                   n_estimators=30000,\n",
        "                                   learning_rate=0.05,\n",
        "                                   num_leaves=2**12-1,\n",
        "                                   colsample_bytree=0.28,\n",
        "                                   objective='binary', \n",
        "                                   n_jobs=-1)\n",
        "                               \n",
        "    lgb_model.fit(X_fit, y_fit, eval_metric='auc', \n",
        "                  eval_set=[(X_val, y_val)], \n",
        "                  verbose=100, early_stopping_rounds=100)\n",
        "                  \n",
        "    oof_1[test_index] += lgb_model.predict_proba(X_val)[:,1]\n",
        "    \n",
        "    del X_fit, X_val, y_fit, y_val, train_index, test_index\n",
        "    gc.collect()\n",
        "    \n",
        "    print('\\nDumping and loading model with pickle...')\n",
        "    # dump model with pickle\n",
        "    with open('/content/gdrive/My Drive/Coding experiment/MARTHA/Models/Checkpoints/lightgbm_checkpoint_'+str(counter)+'.pkl', 'wb') as fout:\n",
        "        pickle.dump(lgb_model, fout)\n",
        "    \n",
        "    print(\"\\nGenerating prediction...\")\n",
        "    test = load_npz('/content/gdrive/My Drive/Coding experiment/MARTHA/test.npz')\n",
        "    test = csr_matrix(test, dtype='float32')\n",
        "    lgb_test_result_1 += lgb_model.predict_proba(test)[:,1]\n",
        "    counter += 1\n",
        "    \n",
        "    del test\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "LightGBM\n",
            "\n",
            "Fold 1\n",
            "\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.604756\tvalid_0's auc: 0.731814\n",
            "[200]\tvalid_0's binary_logloss: 0.598171\tvalid_0's auc: 0.737255\n",
            "[300]\tvalid_0's binary_logloss: 0.596577\tvalid_0's auc: 0.738762\n",
            "[400]\tvalid_0's binary_logloss: 0.596246\tvalid_0's auc: 0.73902\n",
            "[500]\tvalid_0's binary_logloss: 0.596295\tvalid_0's auc: 0.738941\n",
            "Early stopping, best iteration is:\n",
            "[413]\tvalid_0's binary_logloss: 0.596234\tvalid_0's auc: 0.739032\n",
            "\n",
            "Dumping and loading model with pickle...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "c6edc718f1c90b2aa53831728016d1ed2d460bfe",
        "id": "i75SD1qP6qxv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now Build the K Fold Model and generate predictions"
      ]
    },
    {
      "metadata": {
        "_uuid": "4a1275488f221ad9fa199b726cd5f4e19ffc059f",
        "id": "6eFMaVm76qxx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv('../input/sample_submission.csv')\n",
        "submission['HasDetections'] = (lgb_test_result_1 / counter)\n",
        "submission.to_csv('lgb_submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}